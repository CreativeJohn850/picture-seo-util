{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "154791c5-d3a4-4bd9-b6a2-6b34fbd7b1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in c:\\users\\manager\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (11.2.1)\n",
      "Requirement already satisfied: piexif in c:\\users\\manager\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (1.1.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\manager\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (4.67.1)\n",
      "Requirement already satisfied: pathlib in c:\\users\\manager\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\manager\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from tqdm) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Task 1. Setup and Configuration âš™ï¸\n",
    "!pip install Pillow piexif tqdm pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bafe8f2-04ab-4bcb-a6e1-e08f659b1482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-01 12:46:06,877 - INFO - Setup and Configuration loaded successfully.\n",
      "2025-10-01 12:46:06,880 - INFO - Raw Image Path: C:\\wamp64\\www\\media_new\\projects\n",
      "2025-10-01 12:46:06,881 - INFO - Output Path: C:\\wamp64\\www\\media_new\\processed_gallery_images\n",
      "2025-10-01 12:46:06,882 - INFO - Log file created at: C:\\wamp64\\www\\media_new\\processed_gallery_images\\image_processing.log\n"
     ]
    }
   ],
   "source": [
    "# 1.2: Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import pathlib\n",
    "import logging\n",
    "import sys\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS\n",
    "import piexif\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# 1.3: Define I/O Paths and Constants\n",
    "# --- Paths ---\n",
    "# Define the root directory where the original images are stored\n",
    "# IMPORTANT: Replace 'RAW_IMAGE_FOLDER' with the actual path to your 700+ images\n",
    "RAW_IMAGE_FOLDER = pathlib.Path('projects') \n",
    "\n",
    "# Define the path to the projects JSON file (using the uploaded file name)\n",
    "PROJECTS_JSON_FILE = pathlib.Path('projects_full.json') \n",
    "\n",
    "# Define the root directory for all processed, organized, and optimized files\n",
    "OUTPUT_ROOT_FOLDER = pathlib.Path('./processed_gallery_images')\n",
    "\n",
    "# --- Configuration Constants ---\n",
    "MAX_FILE_SIZE_KB = 300\n",
    "MAX_FILE_SIZE_BYTES = MAX_FILE_SIZE_KB * 1024\n",
    "WEBP_QUALITY = 85\n",
    "IMAGE_EXTENSIONS = ('.jpg', '.jpeg', '.png')\n",
    "\n",
    "# --- Logging Setup ---\n",
    "LOG_FILE = OUTPUT_ROOT_FOLDER / 'image_processing.log'\n",
    "# We'll create the output folder here if it doesn't exist yet, to ensure the log file can be written.\n",
    "OUTPUT_ROOT_FOLDER.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(LOG_FILE, mode='w'),\n",
    "        logging.StreamHandler(sys.stdout) # StreamHandler with sys.stdout for better notebook display\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Final Status Print\n",
    "logger.info(\"Setup and Configuration loaded successfully.\")\n",
    "logger.info(f\"Raw Image Path: {RAW_IMAGE_FOLDER.resolve()}\")\n",
    "logger.info(f\"Output Path: {OUTPUT_ROOT_FOLDER.resolve()}\")\n",
    "logger.info(f\"Log file created at: {LOG_FILE.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b27b6cb1-5ab9-4a8e-877b-8dc986b387f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-01 12:46:06,895 - INFO - Starting Task 2: Loading project data.\n",
      "2025-10-01 12:46:06,897 - INFO - Successfully loaded 2 projects from projects.json.\n",
      "2025-10-01 12:46:06,898 - INFO - --- First Project Data Inspection ---\n",
      "2025-10-01 12:46:06,899 - INFO - ID: 101, Slug: hardwood-6-red-oak-101\n",
      "2025-10-01 12:46:06,900 - INFO - Location (Lat/Lon): [41.723119109628875, -88.14503973201094]\n",
      "2025-10-01 12:46:06,901 - INFO - Image Check (f-image): Resized_20190201_180149.jpg\n",
      "2025-10-01 12:46:06,902 - INFO - Image Check (image-00): Resized_20190122_100008.jpg\n",
      "2025-10-01 12:46:06,903 - INFO - -------------------------------------\n",
      "\n",
      "âœ… Project Data Loaded. Total Projects to Process: 2\n"
     ]
    }
   ],
   "source": [
    "# Task 2. Load Project Data ðŸ“‚\n",
    "\n",
    "logger.info(\"Starting Task 2: Loading project data.\")\n",
    "PROJECT_DATA = None\n",
    "PROJECTS_LIST = []\n",
    "\n",
    "try:\n",
    "    with open(PROJECTS_JSON_FILE, 'r', encoding='utf-8') as f:\n",
    "        PROJECT_DATA = json.load(f)\n",
    "        \n",
    "    # Check if the structure has a top-level 'projects' key\n",
    "    if 'projects' in PROJECT_DATA and isinstance(PROJECT_DATA['projects'], list):\n",
    "        PROJECTS_LIST = PROJECT_DATA['projects']\n",
    "        \n",
    "        logger.info(f\"Successfully loaded {len(PROJECTS_LIST)} projects from {PROJECTS_JSON_FILE.name}.\")\n",
    "        \n",
    "        # Display an inspection of the first project for verification\n",
    "        if PROJECTS_LIST:\n",
    "            first_project = PROJECTS_LIST[0]\n",
    "            logger.info(\"--- First Project Data Inspection ---\")\n",
    "            logger.info(f\"ID: {first_project.get('id')}, Slug: {first_project.get('slug')}\")\n",
    "            logger.info(f\"Location (Lat/Lon): {first_project.get('location')}\")\n",
    "            logger.info(f\"Image Check (f-image): {first_project.get('f-image')}\")\n",
    "            logger.info(f\"Image Check (image-00): {first_project.get('image-00')}\")\n",
    "            logger.info(\"-------------------------------------\")\n",
    "            \n",
    "            # Check for critical fields\n",
    "            if not all(key in first_project for key in ['slug', 'location', 'f-image']):\n",
    "                 logger.error(\"CRITICAL ERROR: Required fields ('slug', 'location', 'f-image') are missing in the project data. Stopping.\")\n",
    "                 raise KeyError(\"Missing critical project fields.\")\n",
    "        \n",
    "    else:\n",
    "        logger.error(\"JSON structure error: 'projects' key not found or is not a list.\")\n",
    "        PROJECTS_LIST = []\n",
    "\n",
    "except FileNotFoundError:\n",
    "    logger.error(f\"CRITICAL ERROR: projects_full.json not found at {PROJECTS_JSON_FILE.resolve()}. Cannot proceed.\")\n",
    "    PROJECTS_LIST = []\n",
    "except json.JSONDecodeError:\n",
    "    logger.error(\"CRITICAL ERROR: Failed to decode projects_full.json. Check file formatting.\")\n",
    "    PROJECTS_LIST = []\n",
    "except Exception as e:\n",
    "    logger.error(f\"An unexpected error occurred during data loading: {e}\")\n",
    "    PROJECTS_LIST = []\n",
    "    \n",
    "# Store the total number of projects for the final summary\n",
    "TOTAL_PROJECTS = len(PROJECTS_LIST)\n",
    "\n",
    "print(f\"\\nâœ… Project Data Loaded. Total Projects to Process: {TOTAL_PROJECTS}\")\n",
    "if TOTAL_PROJECTS == 0:\n",
    "    print(\"ðŸ›‘ Please check the log file and ensure 'projects_full.json' is correctly placed and formatted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "381473cd-a8f8-49e9-a26a-929e397abb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "{'id': 301, 'title': 'Refinish Hardwood Dark Walnut Staircase', 'category': 'Staircases', 'excerpt': '3 inch wide red oak, select, dark walnut stain with refinishing of staircase', 'description': '3 inch wide red oak, select, dark walnut stain with refinishing of staircase', 'slug': 'staircases-refinish-red-oak-301', 'location': [41.72397589477297, -88.1439347043486], 'thumb': '.thumb/', 'web': '.web/', 'complete_date': '2024-02-15', 'f-image': 'IMG-370b5014c7c96c16e43c0f4bb8dd6072-V.jpg', 'image-00': 'IMG-0bc6fdd122798a40fe3a1798ac4f4989-V.jpg', 'image-01': 'IMG-1f6c263b9cb4f1171ff6d2d6bfd624c5-V.jpg', 'image-02': 'IMG-2b3a847b2649f41728a6d0a2523b73bd-V.jpg', 'image-03': 'IMG-25c499aeab8e2229ff82fe5ba3816138-V.jpg', 'image-04': 'IMG-95eccb5d975e7227491a9860abbf6d31-V.jpg', 'image-05': 'IMG-97d38db73399dc0974bdf2eb87bcbdbc-V.jpg', 'image-06': 'IMG-d8073c04a34ade1c7d199efb5706067e-V.jpg', 'image-07': 'IMG-dc7917970fc69591d90d050f25ae5f86-V.jpg'}\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Test PROJECTS_LIST length and sample \n",
    "print(len(PROJECTS_LIST))\n",
    "print(PROJECTS_LIST[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad08d0e5-c440-4363-9721-56ad26ccf61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-01 12:46:06,923 - INFO - Starting Task 3: Creating output folders based on project slugs.\n",
      "\n",
      "âœ… Created 2 project folders inside: C:\\wamp64\\www\\media_new\\processed_gallery_images\n"
     ]
    }
   ],
   "source": [
    "# Task 3. Create Project-Specific Folders ðŸ—‚ï¸ - Done successfully\n",
    "\n",
    "logger.info(\"Starting Task 3: Creating output folders based on project slugs.\")\n",
    "folders_created = 0\n",
    "\n",
    "# The OUTPUT_ROOT_FOLDER was already created in the Setup cell, \n",
    "# but we ensure it exists again and then iterate.\n",
    "OUTPUT_ROOT_FOLDER.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Loop through the list of projects and create a directory for each one\n",
    "for project in PROJECTS_LIST:\n",
    "    slug = project.get('slug')\n",
    "    if slug:\n",
    "        project_folder = OUTPUT_ROOT_FOLDER / slug\n",
    "        try:\n",
    "            # Use exist_ok=True so the script doesn't crash if the folder already exists\n",
    "            project_folder.mkdir(exist_ok=True)\n",
    "            folders_created += 1\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to create folder for slug '{slug}': {e}\")\n",
    "    else:\n",
    "        logger.warning(f\"Skipping a project due to missing 'slug' field.\")\n",
    "\n",
    "print(f\"\\nâœ… Created {folders_created} project folders inside: {OUTPUT_ROOT_FOLDER.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79c239b1-93e2-49a5-aecc-4cb45a35d43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Image File Name Extraction Function (4.A) Defined.\n"
     ]
    }
   ],
   "source": [
    "# Task 4.A: Image File Name Extraction Function\n",
    "\n",
    "def get_all_image_names(project):\n",
    "    \"\"\"\n",
    "    Extracts all image file names from a single project dictionary.\n",
    "    This includes the 'f-image' and all 'image-nn' variants.\n",
    "\n",
    "    Args:\n",
    "        project (dict): A single dictionary representing a project's data.\n",
    "\n",
    "    Returns:\n",
    "        list: A unique list of image file names associated with the project.\n",
    "    \"\"\"\n",
    "    image_names = []\n",
    "    \n",
    "    # 1. Main feature image\n",
    "    f_image = project.get('f-image')\n",
    "    if f_image:\n",
    "        image_names.append(f_image)\n",
    "        \n",
    "    # 2. Iterate through image-nn keys (image-00, image-01, etc.)\n",
    "    # We check up to 50, which is a safe, high limit for gallery images\n",
    "    for i in range(50):\n",
    "        # Check padded key (image-00, image-01, ...)\n",
    "        key_padded = f\"image-{i:02d}\"\n",
    "        img_name = project.get(key_padded)\n",
    "        if img_name:\n",
    "            image_names.append(img_name)\n",
    "        \n",
    "        # Check non-padded key (image-10, image-11, image-20) for flexibility in data format\n",
    "        if i >= 10:\n",
    "            key_non_padded = f\"image-{i}\"\n",
    "            img_name_non_padded = project.get(key_non_padded)\n",
    "            # Ensure we don't add duplicates if the padded and non-padded keys point to the same file\n",
    "            if img_name_non_padded and img_name_non_padded not in image_names:\n",
    "                image_names.append(img_name_non_padded)\n",
    "\n",
    "    # Use a set for unique names then convert back to list to handle any duplicate entries\n",
    "    unique_image_names = list(set(image_names))\n",
    "    \n",
    "    logger.debug(f\"Project '{project.get('slug')}': Found {len(unique_image_names)} unique images.\")\n",
    "    \n",
    "    return unique_image_names\n",
    "\n",
    "print(\"\\nâœ… Image File Name Extraction Function (4.A) Defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cfa768e6-53ad-4329-a65c-3dc935bac6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… SEO-Friendly Renaming Function (4.B) Defined and ready.\n"
     ]
    }
   ],
   "source": [
    "# Task 4.B: SEO-Friendly Renaming Function\n",
    "\n",
    "# Define the constant for the mandatory SEO suffix\n",
    "\n",
    "SEO_BRAND_SUFFIX = \"creative-floors-aurora\" \n",
    "\n",
    "def create_seo_name(slug, original_image_name, all_project_images):\n",
    "    \"\"\"\n",
    "    Generates a new, SEO-friendly filename based on the project slug,\n",
    "    image index, and the required brand/location suffix.\n",
    "    \n",
    "    Format: [slug]-[index]-[brand-suffix].webp\n",
    "    Example: hardwood-6-red-oak-101-001-creative-floors-aurora.webp\n",
    "    \n",
    "    Args:\n",
    "        slug (str): The project's unique slug (e.g., 'hardwood-6-red-oak-101').\n",
    "        original_image_name (str): The original filename (e.g., 'Resized_20190122_100008.jpg').\n",
    "        all_project_images (list): Unique list of all image names for the project (from 4.A)\n",
    "                                   used to determine the image's order/index.\n",
    "        \n",
    "    Returns:\n",
    "        str: The new base filename without extension.\n",
    "    \"\"\"\n",
    "    # 1. Determine the image index/role\n",
    "    try:\n",
    "        # Find the index of the current image in the project's list of images\n",
    "        # Adding 1 for a 1-based index (001, 002, ...)\n",
    "        index = all_project_images.index(original_image_name) + 1\n",
    "    except ValueError:\n",
    "        # Fallback if the image name wasn't in the list (shouldn't happen if 4.A is correct)\n",
    "        index = 999 \n",
    "        logger.warning(f\"Could not find {original_image_name} in project list for slug '{slug}'. Using index 999.\")\n",
    "\n",
    "    # Format the index as a three-digit string\n",
    "    index_str = f\"{index:03d}\"\n",
    "    \n",
    "    # 2. Construct the core part of the name\n",
    "    # Format: [slug]-[index]\n",
    "    base_name = f\"{slug}-{index_str}\"\n",
    "    \n",
    "    # 3. Add the required brand/location suffix (Creative Floors Aurora)\n",
    "    # Format: [slug]-[index]-[suffix]\n",
    "    seo_name = f\"{base_name}-{SEO_BRAND_SUFFIX}\"\n",
    "    \n",
    "    logger.debug(f\"Renamed {original_image_name} to base name {seo_name}\")\n",
    "    \n",
    "    return seo_name\n",
    "\n",
    "print(\"\\nâœ… SEO-Friendly Renaming Function (4.B) Defined and ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0517ddb9-a3b0-4576-9585-f10f5e071762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-01 12:46:06,958 - INFO - Successfully collected 7 metadata samples for fallback.\n",
      "\n",
      "âœ… Metadata Sample Scan Complete. 7 samples available.\n"
     ]
    }
   ],
   "source": [
    "# 4.C - 1st\n",
    "\n",
    "import random\n",
    "\n",
    "# Define the path to the folder containing pictures with sample metadata\n",
    "PICTURES_META_FOLDER = pathlib.Path('./pictures_meta')\n",
    "\n",
    "# Check if the folder exists\n",
    "if not PICTURES_META_FOLDER.is_dir():\n",
    "    logger.error(f\"CRITICAL ERROR: Metadata samples folder not found at {PICTURES_META_FOLDER.resolve()}. Cannot proceed with metadata fallback.\")\n",
    "    METADATA_SAMPLES = []\n",
    "else:\n",
    "    # Build a list of all JPEG and PNG files in the samples folder\n",
    "    METADATA_SAMPLES = list(\n",
    "        PICTURES_META_FOLDER.glob('*.jpg')\n",
    "    ) + list(\n",
    "        PICTURES_META_FOLDER.glob('*.jpeg')\n",
    "    ) + list(\n",
    "        PICTURES_META_FOLDER.glob('*.png')\n",
    "    )\n",
    "\n",
    "    if not METADATA_SAMPLES:\n",
    "        logger.warning(f\"Metadata samples folder found, but contains no valid images ({IMAGE_EXTENSIONS}). Metadata fallback will not work.\")\n",
    "    else:\n",
    "        logger.info(f\"Successfully collected {len(METADATA_SAMPLES)} metadata samples for fallback.\")\n",
    "\n",
    "print(f\"\\nâœ… Metadata Sample Scan Complete. {len(METADATA_SAMPLES)} samples available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a69f5f95-6847-4633-9320-2e2eaaf4dcc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Metadata and GPS Insertion Function (4.C) Defined.\n"
     ]
    }
   ],
   "source": [
    "# Task 4.C - 2nd Metadata and GPS Insertion Function\n",
    "\n",
    "def get_exif_with_gps(image_path, latitude, longitude, metadata_sample_path):\n",
    "    \"\"\"\n",
    "    Determines the final EXIF data structure for an image. It either loads\n",
    "    existing metadata, copies it from a sample, and then inserts/updates the GPS location.\n",
    "    \n",
    "    Args:\n",
    "        image_path (pathlib.Path): Path to the original image file.\n",
    "        latitude (float): Project's latitude.\n",
    "        longitude (float): Project's longitude.\n",
    "        metadata_samples (list): List of pathlib.Path objects for sample images.\n",
    "        \n",
    "    Returns:\n",
    "        dict: The complete piexif EXIF dictionary ready to be dumped to bytes.\n",
    "    \"\"\"\n",
    "    # Helper to convert decimal degrees to rational tuple (D, M, S) for EXIF\n",
    "    def to_dms(value):\n",
    "        \"\"\"Converts decimal degrees to a tuple (degrees, minutes, seconds) for EXIF.\"\"\"\n",
    "        if value < 0:\n",
    "            value = -value\n",
    "        d = int(value)\n",
    "        m = int((value - d) * 60)\n",
    "        s = int((value - d - m / 60) * 3600 * 100)\n",
    "        return [(d, 1), (m, 1), (s, 100)]\n",
    "\n",
    "    final_exif_dict = None\n",
    "    \n",
    "    # 1. Load Existing Metadata\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        img_exif_data = img.info.get('exif')\n",
    "        \n",
    "        if img_exif_data:\n",
    "            # piexif.load() will raise an exception if data is malformed\n",
    "            final_exif_dict = piexif.load(img_exif_data)\n",
    "            logger.debug(f\"Loaded existing metadata from {image_path.name}.\")\n",
    "            \n",
    "            # Clean up old GPS data to ensure project coordinates are the source of truth\n",
    "            if \"GPS\" in final_exif_dict:\n",
    "                del final_exif_dict[\"GPS\"] \n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.debug(f\"Could not load valid EXIF data from {image_path.name}: {e}. Attempting fallback.\")\n",
    "\n",
    "    # 2. Conditional Metadata Copy/Fallback\n",
    "    if final_exif_dict is None or not final_exif_dict.get(\"0th\"): # Check if basic 0th IFD is missing\n",
    "        # Check if the single sample path was provided\n",
    "        if metadata_sample_path:\n",
    "            # Use the pre-selected sample path\n",
    "            sample_path = metadata_sample_path\n",
    "            \n",
    "            try:\n",
    "                # Load EXIF data from the pre-selected sample\n",
    "                sample_img = Image.open(sample_path)\n",
    "                sample_exif_data = sample_img.info.get('exif')\n",
    "                \n",
    "                if sample_exif_data:\n",
    "                    # Copy all metadata from the sample\n",
    "                    final_exif_dict = piexif.load(sample_exif_data)\n",
    "                    \n",
    "                    # Remove sample's GPS data (we'll add the project's in step 3)\n",
    "                    if \"GPS\" in final_exif_dict:\n",
    "                        del final_exif_dict[\"GPS\"] \n",
    "                        \n",
    "                    logger.info(f\"Copied metadata from sample: {sample_path.name} for {image_path.name}.\")\n",
    "                else:\n",
    "                    # Fallback to a bare minimum if sample is also empty\n",
    "                    final_exif_dict = {\"0th\": {}, \"Exif\": {}, \"GPS\": {}, \"1st\": {}}\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Error loading sample metadata from {sample_path.name}: {e}. Using minimum metadata.\")\n",
    "                final_exif_dict = {\"0th\": {}, \"Exif\": {}, \"GPS\": {}, \"1st\": {}}\n",
    "        else:\n",
    "            # Final resort: use a bare minimum EXIF dictionary\n",
    "            final_exif_dict = {\"0th\": {}, \"Exif\": {}, \"GPS\": {}, \"1st\": {}}\n",
    "            logger.warning(f\"No metadata found/copied for {image_path.name}. Using minimum EXIF structure.\")\n",
    "\n",
    "    # 3. GPS Conversion and Insertion (This step always runs)\n",
    "    \n",
    "    # Convert coordinates to DMS format\n",
    "    lat_dms = to_dms(latitude)\n",
    "    lon_dms = to_dms(longitude)\n",
    "\n",
    "    # Determine reference (N/S, E/W)\n",
    "    lat_ref = 'N' if latitude >= 0 else 'S'\n",
    "    lon_ref = 'E' if longitude >= 0 else 'W'\n",
    "\n",
    "    # Create the GPS IFD (Image File Directory) dictionary\n",
    "    gps_ifd = {\n",
    "        piexif.GPSIFD.GPSLatitudeRef: lat_ref,\n",
    "        piexif.GPSIFD.GPSLatitude: lat_dms,\n",
    "        piexif.GPSIFD.GPSLongitudeRef: lon_ref,\n",
    "        piexif.GPSIFD.GPSLongitude: lon_dms,\n",
    "        # Standard GPS Version ID, required by specification\n",
    "        piexif.GPSIFD.GPSVersionID: (2, 2, 0, 0)\n",
    "    }\n",
    "    \n",
    "    # Update the final dictionary with the project's GPS data\n",
    "    final_exif_dict[\"GPS\"] = gps_ifd\n",
    "    \n",
    "    logger.debug(f\"Attached GPS data to EXIF dict: Lat={latitude}, Lon={longitude}\")\n",
    "    \n",
    "    return final_exif_dict\n",
    "\n",
    "print(\"\\nâœ… Metadata and GPS Insertion Function (4.C) Defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9bd5d14-3e27-42d7-b13e-153af6c93a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Optimization, Conversion, and Saving Function (4.D) Defined.\n"
     ]
    }
   ],
   "source": [
    "# Task 4.D: Optimization, Conversion, and Saving Function\n",
    "\n",
    "# Note: This function relies on MAX_FILE_SIZE_BYTES, WEBP_QUALITY, \n",
    "# and the get_exif_with_gps function (4.C) being defined in previous cells.\n",
    "\n",
    "def process_single_image(original_image_name, project_slug, lat, lon, seo_name, metadata_sample_path):\n",
    "    \"\"\"\n",
    "    Handles the end-to-end processing of a single image file: \n",
    "    1. Gets/Copies EXIF data and adds GPS.\n",
    "    2. Opens and optimizes the image (resizing if too large).\n",
    "    3. Converts to WEBP.\n",
    "    4. Saves the final file to the project's folder.\n",
    "    \n",
    "    Args:\n",
    "        original_image_name (str): The filename from the JSON (e.g., 'sample.jpg').\n",
    "        project_slug (str): The project's slug for the output folder.\n",
    "        lat (float): Project latitude.\n",
    "        lon (float): Project longitude.\n",
    "        seo_name (str): The new SEO-friendly base name (from 4.B).\n",
    "        metadata_samples (list): List of sample image paths for EXIF fallback.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (bool success, str status_message, str final_file_name)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Setup Paths\n",
    "    # We must find the full path to the source file (e.g., './RAW_IMAGE_FOLDER/sample.jpg')\n",
    "    source_path = RAW_IMAGE_FOLDER / original_image_name\n",
    "    target_folder = OUTPUT_ROOT_FOLDER / project_slug\n",
    "    final_file_name = f\"{seo_name}.webp\"\n",
    "    final_target_path = target_folder / final_file_name\n",
    "\n",
    "    # Check if the source file exists and has an acceptable extension\n",
    "    if not source_path.is_file() or source_path.suffix.lower() not in IMAGE_EXTENSIONS:\n",
    "        return False, f\"Source file not found or extension not supported: {original_image_name}\", final_file_name\n",
    "\n",
    "    original_size = source_path.stat().st_size\n",
    "    was_resized = False\n",
    "    \n",
    "    try:\n",
    "        # 2. Get EXIF Data (calls 4.C)\n",
    "        final_exif_dict = get_exif_with_gps(source_path, lat, lon, metadata_sample_path)\n",
    "        \n",
    "        # Convert EXIF dictionary back into binary format for saving\n",
    "        exif_bytes = piexif.dump(final_exif_dict)\n",
    "        \n",
    "        # 3. Open Image\n",
    "        img = Image.open(source_path)\n",
    "        width, height = img.size\n",
    "        \n",
    "        # 4. Size Reduction (Scaling): If file size > 300KB, reduce resolution\n",
    "        if original_size > MAX_FILE_SIZE_BYTES:\n",
    "            # We target a max width of 1920px if the image is excessively large, \n",
    "            # as this is a common compromise for web display speed.\n",
    "            MAX_RESIZE_WIDTH = 1920\n",
    "            \n",
    "            if width > MAX_RESIZE_WIDTH:\n",
    "                scale_factor = MAX_RESIZE_WIDTH / width\n",
    "                new_width = MAX_RESIZE_WIDTH\n",
    "                new_height = int(height * scale_factor)\n",
    "                \n",
    "                # Use a high-quality resampling filter (LANCZOS)\n",
    "                img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "                was_resized = True\n",
    "                logger.info(f\"Resized: {original_image_name} from {width}x{height} to {new_width}x{new_height}.\")\n",
    "        \n",
    "        # 5. Handle PNG/Transparency\n",
    "        if img.mode in ('RGBA', 'P') or source_path.suffix.lower() == '.png':\n",
    "            # Create a white background and paste the image, removing the alpha channel\n",
    "            background = Image.new('RGB', img.size, (255, 255, 255))\n",
    "            # Use the alpha channel as a mask if it exists\n",
    "            background.paste(img, mask=img.split()[3] if 'A' in img.mode else None)\n",
    "            img = background\n",
    "            logger.debug(\"Converted image to RGB (removed transparency) for WEBP conversion.\")\n",
    "        \n",
    "        # 6. Convert and Save (WEBP)\n",
    "        img.save(\n",
    "            final_target_path, \n",
    "            \"webp\", \n",
    "            quality=WEBP_QUALITY, \n",
    "            exif=exif_bytes,\n",
    "            method=6 # Use a slightly slower but often better compression method\n",
    "        )\n",
    "\n",
    "        # 7. Final Verification and Status\n",
    "        final_size = final_target_path.stat().st_size\n",
    "        \n",
    "        status_msg = (\n",
    "            f\"Processed successfully. Orig size: {original_size/1024:.1f} KB. \"\n",
    "            f\"Final size: {final_size/1024:.1f} KB. \"\n",
    "            f\"Action: {'Resized and Converted' if was_resized else 'Converted only'}.\"\n",
    "        )\n",
    "        \n",
    "        return True, status_msg, final_file_name\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Catch any failure during the image processing, metadata stamping, or saving\n",
    "        return False, f\"Critical processing error for {original_image_name}: {e}\", final_file_name\n",
    "\n",
    "print(\"\\nâœ… Optimization, Conversion, and Saving Function (4.D) Defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37fbccff-a09c-4c35-a7cd-8ae99f143dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-01 12:46:07,034 - INFO - Starting Task 4: Main Image Processing Pipeline.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ef89ad509a46ca9ceb2a074644fe70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Overall Projects Progress:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-01 12:46:07,059 - INFO - --- Processing Project: hardwood-6-red-oak-101 (8 images) ---\n",
      "2025-10-01 12:46:07,065 - INFO - Copied metadata from sample: IMG_4122.jpg for Resized_20190122_131807.jpg.\n",
      "2025-10-01 12:46:07,259 - INFO - SUCCESS: hardwood-6-red-oak-101-001-creative-floors-aurora.webp -> Processed successfully. Orig size: 273.2 KB. Final size: 51.5 KB. Action: Converted only.\n",
      "2025-10-01 12:46:07,260 - INFO - Copied metadata from sample: IMG_4122.jpg for Resized_20190122_131816.jpg.\n",
      "2025-10-01 12:46:07,424 - INFO - SUCCESS: hardwood-6-red-oak-101-002-creative-floors-aurora.webp -> Processed successfully. Orig size: 459.6 KB. Final size: 68.0 KB. Action: Converted only.\n",
      "2025-10-01 12:46:07,426 - INFO - Copied metadata from sample: IMG_4122.jpg for Resized_20190122_100008.jpg.\n",
      "2025-10-01 12:46:07,640 - INFO - SUCCESS: hardwood-6-red-oak-101-003-creative-floors-aurora.webp -> Processed successfully. Orig size: 567.6 KB. Final size: 113.3 KB. Action: Converted only.\n",
      "2025-10-01 12:46:07,643 - INFO - Copied metadata from sample: IMG_4122.jpg for Resized_20190201_175718.jpg.\n",
      "2025-10-01 12:46:07,842 - INFO - SUCCESS: hardwood-6-red-oak-101-004-creative-floors-aurora.webp -> Processed successfully. Orig size: 171.7 KB. Final size: 97.2 KB. Action: Converted only.\n",
      "2025-10-01 12:46:07,843 - INFO - Copied metadata from sample: IMG_4122.jpg for Resized_20190122_131756.jpg.\n",
      "2025-10-01 12:46:07,991 - INFO - SUCCESS: hardwood-6-red-oak-101-005-creative-floors-aurora.webp -> Processed successfully. Orig size: 243.2 KB. Final size: 44.2 KB. Action: Converted only.\n",
      "2025-10-01 12:46:07,993 - INFO - Copied metadata from sample: IMG_4122.jpg for Resized_20190201_175706.jpg.\n",
      "2025-10-01 12:46:08,246 - INFO - SUCCESS: hardwood-6-red-oak-101-006-creative-floors-aurora.webp -> Processed successfully. Orig size: 539.4 KB. Final size: 108.6 KB. Action: Converted only.\n",
      "2025-10-01 12:46:08,248 - INFO - Copied metadata from sample: IMG_4122.jpg for Resized_20190201_180149.jpg.\n",
      "2025-10-01 12:46:08,485 - INFO - SUCCESS: hardwood-6-red-oak-101-007-creative-floors-aurora.webp -> Processed successfully. Orig size: 547.3 KB. Final size: 110.6 KB. Action: Converted only.\n",
      "2025-10-01 12:46:08,487 - INFO - Copied metadata from sample: IMG_4122.jpg for Resized_20190201_175815.jpg.\n",
      "2025-10-01 12:46:08,646 - INFO - SUCCESS: hardwood-6-red-oak-101-008-creative-floors-aurora.webp -> Processed successfully. Orig size: 183.5 KB. Final size: 53.8 KB. Action: Converted only.\n",
      "2025-10-01 12:46:08,648 - INFO - --- Processing Project: staircases-refinish-red-oak-301 (9 images) ---\n",
      "2025-10-01 12:46:08,651 - INFO - Copied metadata from sample: DSC_0607.jpg for IMG-97d38db73399dc0974bdf2eb87bcbdbc-V.jpg.\n",
      "2025-10-01 12:46:08,889 - INFO - SUCCESS: staircases-refinish-red-oak-301-001-creative-floors-aurora.webp -> Processed successfully. Orig size: 181.3 KB. Final size: 92.2 KB. Action: Converted only.\n",
      "2025-10-01 12:46:08,891 - INFO - Copied metadata from sample: DSC_0607.jpg for IMG-0bc6fdd122798a40fe3a1798ac4f4989-V.jpg.\n",
      "2025-10-01 12:46:09,197 - INFO - SUCCESS: staircases-refinish-red-oak-301-002-creative-floors-aurora.webp -> Processed successfully. Orig size: 240.0 KB. Final size: 144.3 KB. Action: Converted only.\n",
      "2025-10-01 12:46:09,200 - INFO - Copied metadata from sample: DSC_0607.jpg for IMG-25c499aeab8e2229ff82fe5ba3816138-V.jpg.\n",
      "2025-10-01 12:46:09,504 - INFO - SUCCESS: staircases-refinish-red-oak-301-003-creative-floors-aurora.webp -> Processed successfully. Orig size: 189.0 KB. Final size: 136.0 KB. Action: Converted only.\n",
      "2025-10-01 12:46:09,506 - INFO - Copied metadata from sample: DSC_0607.jpg for IMG-d8073c04a34ade1c7d199efb5706067e-V.jpg.\n",
      "2025-10-01 12:46:09,847 - INFO - SUCCESS: staircases-refinish-red-oak-301-004-creative-floors-aurora.webp -> Processed successfully. Orig size: 199.8 KB. Final size: 161.6 KB. Action: Converted only.\n",
      "2025-10-01 12:46:09,850 - INFO - Copied metadata from sample: DSC_0607.jpg for IMG-dc7917970fc69591d90d050f25ae5f86-V.jpg.\n",
      "2025-10-01 12:46:10,110 - INFO - SUCCESS: staircases-refinish-red-oak-301-005-creative-floors-aurora.webp -> Processed successfully. Orig size: 204.5 KB. Final size: 106.3 KB. Action: Converted only.\n",
      "2025-10-01 12:46:10,112 - INFO - Copied metadata from sample: DSC_0607.jpg for IMG-95eccb5d975e7227491a9860abbf6d31-V.jpg.\n",
      "2025-10-01 12:46:10,423 - INFO - SUCCESS: staircases-refinish-red-oak-301-006-creative-floors-aurora.webp -> Processed successfully. Orig size: 238.7 KB. Final size: 128.7 KB. Action: Converted only.\n",
      "2025-10-01 12:46:10,425 - INFO - Copied metadata from sample: DSC_0607.jpg for IMG-370b5014c7c96c16e43c0f4bb8dd6072-V.jpg.\n",
      "2025-10-01 12:46:10,697 - INFO - SUCCESS: staircases-refinish-red-oak-301-007-creative-floors-aurora.webp -> Processed successfully. Orig size: 218.1 KB. Final size: 97.5 KB. Action: Converted only.\n",
      "2025-10-01 12:46:10,699 - INFO - Copied metadata from sample: DSC_0607.jpg for IMG-2b3a847b2649f41728a6d0a2523b73bd-V.jpg.\n",
      "2025-10-01 12:46:11,046 - INFO - SUCCESS: staircases-refinish-red-oak-301-008-creative-floors-aurora.webp -> Processed successfully. Orig size: 186.7 KB. Final size: 156.9 KB. Action: Converted only.\n",
      "2025-10-01 12:46:11,048 - INFO - Copied metadata from sample: DSC_0607.jpg for IMG-1f6c263b9cb4f1171ff6d2d6bfd624c5-V.jpg.\n",
      "2025-10-01 12:46:11,256 - INFO - SUCCESS: staircases-refinish-red-oak-301-009-creative-floors-aurora.webp -> Processed successfully. Orig size: 154.4 KB. Final size: 65.0 KB. Action: Converted only.\n",
      "\n",
      "==================================================\n",
      "             âœ¨ PROCESSING SUMMARY âœ¨\n",
      "==================================================\n",
      "Total Projects:             2\n",
      "Total Images Expected:      17\n",
      "--------------------------------------------------\n",
      "âœ… Images Successfully Processed: 17\n",
      "âŒ Images Failed/Skipped:       0\n",
      "\n",
      "Output Folder:\n",
      "   C:\\wamp64\\www\\media_new\\processed_gallery_images\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Task 4.E: Main Processing Loop\n",
    "\n",
    "logger.info(\"Starting Task 4: Main Image Processing Pipeline.\")\n",
    "\n",
    "# Initialize global counters\n",
    "total_images_found = 0\n",
    "images_processed_success = 0\n",
    "images_processed_failed = 0\n",
    "\n",
    "# Use tqdm (or the DummyTqdm fallback) to show progress across all projects\n",
    "for project in tqdm(PROJECTS_LIST, desc=\"Overall Projects Progress\"):\n",
    "    \n",
    "    slug = project.get('slug')\n",
    "    location = project.get('location', [41.74141971915897, -88.22985634634969]) # Default to Creative Floors HQ\n",
    "    lat, lon = location[0], location[1]\n",
    "    \n",
    "    if not slug or lat is None or lon is None:\n",
    "        logger.error(f\"Skipping project due to missing slug or location data: ID={project.get('id')}.\")\n",
    "        continue\n",
    "    # Select one metadata sample for the entire project\n",
    "    selected_metadata_sample = random.choice(METADATA_SAMPLES) if METADATA_SAMPLES else None\n",
    "    \n",
    "    # 1. Get the list of original image file names (using 4.A)\n",
    "    original_image_names = get_all_image_names(project)\n",
    "    total_images_found += len(original_image_names)\n",
    "    \n",
    "    # Check if any images were found\n",
    "    if not original_image_names:\n",
    "        logger.info(f\"Project '{slug}' has no associated images listed. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    logger.info(f\"--- Processing Project: {slug} ({len(original_image_names)} images) ---\")\n",
    "\n",
    "    # Inner loop: Iterate over all images found for the current project\n",
    "    for original_image_name in original_image_names:\n",
    "        \n",
    "        # 2. Generate SEO-friendly file name (using 4.B)\n",
    "        seo_name = create_seo_name(slug, original_image_name, original_image_names)\n",
    "\n",
    "        # 3. Execute the full processing pipeline (uses 4.C and 4.D logic)\n",
    "        success, status_msg, final_file_name = process_single_image(\n",
    "            original_image_name=original_image_name, \n",
    "            project_slug=slug, \n",
    "            lat=lat, \n",
    "            lon=lon, \n",
    "            seo_name=seo_name, \n",
    "            metadata_sample_path=selected_metadata_sample\n",
    "        )\n",
    "        \n",
    "        # 4. Update Counters and Log\n",
    "        if success:\n",
    "            images_processed_success += 1\n",
    "            logger.info(f\"SUCCESS: {final_file_name} -> {status_msg}\")\n",
    "        else:\n",
    "            images_processed_failed += 1\n",
    "            logger.warning(f\"FAILURE: {original_image_name} -> {status_msg}\")\n",
    "\n",
    "# Final summary printout\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"             âœ¨ PROCESSING SUMMARY âœ¨\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total Projects:             {TOTAL_PROJECTS}\")\n",
    "print(f\"Total Images Expected:      {total_images_found}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"âœ… Images Successfully Processed: {images_processed_success}\")\n",
    "print(f\"âŒ Images Failed/Skipped:       {images_processed_failed}\")\n",
    "print(\"\\nOutput Folder:\")\n",
    "print(f\"   {OUTPUT_ROOT_FOLDER.resolve()}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if images_processed_failed > 0:\n",
    "    print(\"WARNING: Check the detailed log file (image_processing.log) for failure reasons.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4767c775-15b0-4388-9234-713bf57338af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
