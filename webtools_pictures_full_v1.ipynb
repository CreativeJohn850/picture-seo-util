{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "154791c5-d3a4-4bd9-b6a2-6b34fbd7b1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in c:\\users\\manager\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (11.2.1)\n",
      "Requirement already satisfied: piexif in c:\\users\\manager\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (1.1.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\manager\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (4.67.1)\n",
      "Requirement already satisfied: pathlib in c:\\users\\manager\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\manager\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from tqdm) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Task 1. Setup and Configuration ‚öôÔ∏è\n",
    "!pip install Pillow piexif tqdm pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6bafe8f2-04ab-4bcb-a6e1-e08f659b1482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-01 17:03:35,989 - INFO - Setup and Configuration loaded successfully.\n",
      "2025-10-01 17:03:35,992 - INFO - Raw Image Path: C:\\wamp64\\www\\media_new\\projects\\2025\\F2Poly\n",
      "2025-10-01 17:03:35,993 - INFO - Output Path: C:\\wamp64\\www\\media_new\\processed_gallery_images\n",
      "2025-10-01 17:03:35,994 - INFO - Log file created at: C:\\wamp64\\www\\media_new\\processed_gallery_images\\image_processing.log\n"
     ]
    }
   ],
   "source": [
    "# 1.2: Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import pathlib\n",
    "import logging\n",
    "import sys\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS\n",
    "import piexif\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# 1.3: Define I/O Paths and Constants\n",
    "# --- Paths ---\n",
    "# Define the root directory where the original images are stored\n",
    "# IMPORTANT: Replace 'RAW_IMAGE_FOLDER' with the actual path to your 700+ images\n",
    "RAW_IMAGE_FOLDER = pathlib.Path('projects/2025/F2Poly/') \n",
    "\n",
    "# Define the path to the projects JSON file (using the uploaded file name)\n",
    "PROJECTS_JSON_FILE = pathlib.Path('projects_left_behind.json') \n",
    "\n",
    "# Define the root directory for all processed, organized, and optimized files\n",
    "OUTPUT_ROOT_FOLDER = pathlib.Path('./processed_gallery_images')\n",
    "\n",
    "# --- Configuration Constants ---\n",
    "MAX_FILE_SIZE_KB = 300\n",
    "MAX_FILE_SIZE_BYTES = MAX_FILE_SIZE_KB * 1024\n",
    "WEBP_QUALITY = 85\n",
    "IMAGE_EXTENSIONS = ('.jpg', '.jpeg', '.png')\n",
    "\n",
    "# --- Logging Setup ---\n",
    "LOG_FILE = OUTPUT_ROOT_FOLDER / 'image_processing.log'\n",
    "# We'll create the output folder here if it doesn't exist yet, to ensure the log file can be written.\n",
    "OUTPUT_ROOT_FOLDER.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(LOG_FILE, mode='w'),\n",
    "        logging.StreamHandler(sys.stdout) # StreamHandler with sys.stdout for better notebook display\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Final Status Print\n",
    "logger.info(\"Setup and Configuration loaded successfully.\")\n",
    "logger.info(f\"Raw Image Path: {RAW_IMAGE_FOLDER.resolve()}\")\n",
    "logger.info(f\"Output Path: {OUTPUT_ROOT_FOLDER.resolve()}\")\n",
    "logger.info(f\"Log file created at: {LOG_FILE.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b27b6cb1-5ab9-4a8e-877b-8dc986b387f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-01 17:03:36,005 - INFO - Starting Task 2: Loading project data.\n",
      "2025-10-01 17:03:36,006 - INFO - Successfully loaded 1 projects from projects_left_behind.json.\n",
      "2025-10-01 17:03:36,008 - INFO - --- First Project Data Inspection ---\n",
      "2025-10-01 17:03:36,009 - INFO - ID: 406, Slug: polyester-carpet-dreamweaver-406\n",
      "2025-10-01 17:03:36,010 - INFO - Location (Lat/Lon): [41.768558989989465, -88.14980582160743]\n",
      "2025-10-01 17:03:36,011 - INFO - Image Check (f-image): giese (1).jpg\n",
      "2025-10-01 17:03:36,012 - INFO - Image Check (image-00): bond (2).jpg\n",
      "2025-10-01 17:03:36,013 - INFO - -------------------------------------\n",
      "\n",
      "‚úÖ Project Data Loaded. Total Projects to Process: 1\n"
     ]
    }
   ],
   "source": [
    "# Task 2. Load Project Data üìÇ\n",
    "\n",
    "logger.info(\"Starting Task 2: Loading project data.\")\n",
    "PROJECT_DATA = None\n",
    "PROJECTS_LIST = []\n",
    "\n",
    "try:\n",
    "    with open(PROJECTS_JSON_FILE, 'r', encoding='utf-8') as f:\n",
    "        PROJECT_DATA = json.load(f)\n",
    "        \n",
    "    # Check if the structure has a top-level 'projects' key\n",
    "    if 'projects' in PROJECT_DATA and isinstance(PROJECT_DATA['projects'], list):\n",
    "        PROJECTS_LIST = PROJECT_DATA['projects']\n",
    "        \n",
    "        logger.info(f\"Successfully loaded {len(PROJECTS_LIST)} projects from {PROJECTS_JSON_FILE.name}.\")\n",
    "        \n",
    "        # Display an inspection of the first project for verification\n",
    "        if PROJECTS_LIST:\n",
    "            first_project = PROJECTS_LIST[0]\n",
    "            logger.info(\"--- First Project Data Inspection ---\")\n",
    "            logger.info(f\"ID: {first_project.get('id')}, Slug: {first_project.get('slug')}\")\n",
    "            logger.info(f\"Location (Lat/Lon): {first_project.get('location')}\")\n",
    "            logger.info(f\"Image Check (f-image): {first_project.get('f-image')}\")\n",
    "            logger.info(f\"Image Check (image-00): {first_project.get('image-00')}\")\n",
    "            logger.info(\"-------------------------------------\")\n",
    "            \n",
    "            # Check for critical fields\n",
    "            if not all(key in first_project for key in ['slug', 'location', 'f-image']):\n",
    "                 logger.error(\"CRITICAL ERROR: Required fields ('slug', 'location', 'f-image') are missing in the project data. Stopping.\")\n",
    "                 raise KeyError(\"Missing critical project fields.\")\n",
    "        \n",
    "    else:\n",
    "        logger.error(\"JSON structure error: 'projects' key not found or is not a list.\")\n",
    "        PROJECTS_LIST = []\n",
    "\n",
    "except FileNotFoundError:\n",
    "    logger.error(f\"CRITICAL ERROR: projects_full.json not found at {PROJECTS_JSON_FILE.resolve()}. Cannot proceed.\")\n",
    "    PROJECTS_LIST = []\n",
    "except json.JSONDecodeError:\n",
    "    logger.error(\"CRITICAL ERROR: Failed to decode projects_full.json. Check file formatting.\")\n",
    "    PROJECTS_LIST = []\n",
    "except Exception as e:\n",
    "    logger.error(f\"An unexpected error occurred during data loading: {e}\")\n",
    "    PROJECTS_LIST = []\n",
    "    \n",
    "# Store the total number of projects for the final summary\n",
    "TOTAL_PROJECTS = len(PROJECTS_LIST)\n",
    "\n",
    "print(f\"\\n‚úÖ Project Data Loaded. Total Projects to Process: {TOTAL_PROJECTS}\")\n",
    "if TOTAL_PROJECTS == 0:\n",
    "    print(\"üõë Please check the log file and ensure 'projects_full.json' is correctly placed and formatted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "381473cd-a8f8-49e9-a26a-929e397abb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "{'id': 406, 'title': 'Polyester Carpet by Dreamweaver Basement', 'category': 'Carpet', 'excerpt': 'Multiple projects featuring polyester carpet by Dreamweaver, for bedrooms, hallways, basement and even steps.', 'description': 'Multiple projects featuring polyester carpet by Dreamweaver, for bedrooms, hallways, basement and even steps.', 'slug': 'polyester-carpet-dreamweaver-406', 'location': [41.768558989989465, -88.14980582160743], 'thumb': '2025/F2Poly/thumb/', 'web': '2025/F2Poly/', 'complete_date': '2025-02-20', 'f-image': 'giese (1).jpg', 'image-00': 'bond (2).jpg', 'image-01': 'bond (3).jpg', 'image-02': 'crott (1).jpg', 'image-03': 'crott (2).jpg', 'image-04': 'crott (3).jpg', 'image-05': 'crott (4).jpg', 'image-06': 'bond (1).jpg', 'image-07': 'giese (2).jpg', 'image-08': 'giese (3).jpg', 'image-09': 'giese (4).jpg'}\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Test PROJECTS_LIST length and sample \n",
    "print(len(PROJECTS_LIST))\n",
    "print(PROJECTS_LIST[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ad08d0e5-c440-4363-9721-56ad26ccf61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-01 17:03:36,030 - INFO - Starting Task 3: Creating output folders based on project slugs.\n",
      "\n",
      "‚úÖ Created 1 project folders inside: C:\\wamp64\\www\\media_new\\processed_gallery_images\n"
     ]
    }
   ],
   "source": [
    "# Task 3. Create Project-Specific Folders üóÇÔ∏è - Done successfully\n",
    "\n",
    "logger.info(\"Starting Task 3: Creating output folders based on project slugs.\")\n",
    "folders_created = 0\n",
    "\n",
    "# The OUTPUT_ROOT_FOLDER was already created in the Setup cell, \n",
    "# but we ensure it exists again and then iterate.\n",
    "OUTPUT_ROOT_FOLDER.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Loop through the list of projects and create a directory for each one\n",
    "for project in PROJECTS_LIST:\n",
    "    slug = project.get('slug')\n",
    "    if slug:\n",
    "        project_folder = OUTPUT_ROOT_FOLDER / slug\n",
    "        try:\n",
    "            # Use exist_ok=True so the script doesn't crash if the folder already exists\n",
    "            project_folder.mkdir(exist_ok=True)\n",
    "            folders_created += 1\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to create folder for slug '{slug}': {e}\")\n",
    "    else:\n",
    "        logger.warning(f\"Skipping a project due to missing 'slug' field.\")\n",
    "\n",
    "print(f\"\\n‚úÖ Created {folders_created} project folders inside: {OUTPUT_ROOT_FOLDER.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "79c239b1-93e2-49a5-aecc-4cb45a35d43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Image File Name Extraction Function (4.A) Defined.\n"
     ]
    }
   ],
   "source": [
    "# Task 4.A: Image File Name Extraction Function\n",
    "\n",
    "def get_all_image_names(project):\n",
    "    \"\"\"\n",
    "    Extracts all image file names from a single project dictionary.\n",
    "    This includes the 'f-image' and all 'image-nn' variants.\n",
    "\n",
    "    Args:\n",
    "        project (dict): A single dictionary representing a project's data.\n",
    "\n",
    "    Returns:\n",
    "        list: A unique list of image file names associated with the project.\n",
    "    \"\"\"\n",
    "    image_names = []\n",
    "    \n",
    "    # 1. Main feature image\n",
    "    f_image = project.get('f-image')\n",
    "    if f_image:\n",
    "        image_names.append(f_image)\n",
    "        \n",
    "    # 2. Iterate through image-nn keys (image-00, image-01, etc.)\n",
    "    # We check up to 50, which is a safe, high limit for gallery images\n",
    "    for i in range(50):\n",
    "        # Check padded key (image-00, image-01, ...)\n",
    "        key_padded = f\"image-{i:02d}\"\n",
    "        img_name = project.get(key_padded)\n",
    "        if img_name:\n",
    "            image_names.append(img_name)\n",
    "        \n",
    "        # Check non-padded key (image-10, image-11, image-20) for flexibility in data format\n",
    "        if i >= 10:\n",
    "            key_non_padded = f\"image-{i}\"\n",
    "            img_name_non_padded = project.get(key_non_padded)\n",
    "            # Ensure we don't add duplicates if the padded and non-padded keys point to the same file\n",
    "            if img_name_non_padded and img_name_non_padded not in image_names:\n",
    "                image_names.append(img_name_non_padded)\n",
    "\n",
    "    # Use a set for unique names then convert back to list to handle any duplicate entries\n",
    "    unique_image_names = list(set(image_names))\n",
    "    \n",
    "    logger.debug(f\"Project '{project.get('slug')}': Found {len(unique_image_names)} unique images.\")\n",
    "    \n",
    "    return unique_image_names\n",
    "\n",
    "print(\"\\n‚úÖ Image File Name Extraction Function (4.A) Defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "cfa768e6-53ad-4329-a65c-3dc935bac6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ SEO-Friendly Renaming Function (4.B) Defined and ready.\n"
     ]
    }
   ],
   "source": [
    "# Task 4.B: SEO-Friendly Renaming Function\n",
    "\n",
    "# Define the constant for the mandatory SEO suffix\n",
    "\n",
    "SEO_BRAND_SUFFIX = \"creative-floors-aurora\" \n",
    "\n",
    "def create_seo_name(slug, original_image_name, all_project_images):\n",
    "    \"\"\"\n",
    "    Generates a new, SEO-friendly filename based on the project slug,\n",
    "    image index, and the required brand/location suffix.\n",
    "    \n",
    "    Format: [slug]-[index]-[brand-suffix].webp\n",
    "    Example: hardwood-6-red-oak-101-001-creative-floors-aurora.webp\n",
    "    \n",
    "    Args:\n",
    "        slug (str): The project's unique slug (e.g., 'hardwood-6-red-oak-101').\n",
    "        original_image_name (str): The original filename (e.g., 'Resized_20190122_100008.jpg').\n",
    "        all_project_images (list): Unique list of all image names for the project (from 4.A)\n",
    "                                   used to determine the image's order/index.\n",
    "        \n",
    "    Returns:\n",
    "        str: The new base filename without extension.\n",
    "    \"\"\"\n",
    "    # 1. Determine the image index/role\n",
    "    try:\n",
    "        # Find the index of the current image in the project's list of images\n",
    "        # Adding 1 for a 1-based index (001, 002, ...)\n",
    "        index = all_project_images.index(original_image_name) + 1\n",
    "    except ValueError:\n",
    "        # Fallback if the image name wasn't in the list (shouldn't happen if 4.A is correct)\n",
    "        index = 999 \n",
    "        logger.warning(f\"Could not find {original_image_name} in project list for slug '{slug}'. Using index 999.\")\n",
    "\n",
    "    # Format the index as a three-digit string\n",
    "    index_str = f\"{index:03d}\"\n",
    "    \n",
    "    # 2. Construct the core part of the name\n",
    "    # Format: [slug]-[index]\n",
    "    base_name = f\"{slug}-{index_str}\"\n",
    "    \n",
    "    # 3. Add the required brand/location suffix (Creative Floors Aurora)\n",
    "    # Format: [slug]-[index]-[suffix]\n",
    "    seo_name = f\"{base_name}-{SEO_BRAND_SUFFIX}\"\n",
    "    \n",
    "    logger.debug(f\"Renamed {original_image_name} to base name {seo_name}\")\n",
    "    \n",
    "    return seo_name\n",
    "\n",
    "print(\"\\n‚úÖ SEO-Friendly Renaming Function (4.B) Defined and ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "0517ddb9-a3b0-4576-9585-f10f5e071762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-01 17:03:36,061 - INFO - Successfully collected 7 metadata samples for fallback.\n",
      "\n",
      "‚úÖ Metadata Sample Scan Complete. 7 samples available.\n"
     ]
    }
   ],
   "source": [
    "# 4.C - 1st\n",
    "\n",
    "import random\n",
    "\n",
    "# Define the path to the folder containing pictures with sample metadata\n",
    "PICTURES_META_FOLDER = pathlib.Path('./pictures_meta')\n",
    "\n",
    "# Check if the folder exists\n",
    "if not PICTURES_META_FOLDER.is_dir():\n",
    "    logger.error(f\"CRITICAL ERROR: Metadata samples folder not found at {PICTURES_META_FOLDER.resolve()}. Cannot proceed with metadata fallback.\")\n",
    "    METADATA_SAMPLES = []\n",
    "else:\n",
    "    # Build a list of all JPEG and PNG files in the samples folder\n",
    "    METADATA_SAMPLES = list(\n",
    "        PICTURES_META_FOLDER.glob('*.jpg')\n",
    "    ) + list(\n",
    "        PICTURES_META_FOLDER.glob('*.jpeg')\n",
    "    ) + list(\n",
    "        PICTURES_META_FOLDER.glob('*.png')\n",
    "    )\n",
    "\n",
    "    if not METADATA_SAMPLES:\n",
    "        logger.warning(f\"Metadata samples folder found, but contains no valid images ({IMAGE_EXTENSIONS}). Metadata fallback will not work.\")\n",
    "    else:\n",
    "        logger.info(f\"Successfully collected {len(METADATA_SAMPLES)} metadata samples for fallback.\")\n",
    "\n",
    "print(f\"\\n‚úÖ Metadata Sample Scan Complete. {len(METADATA_SAMPLES)} samples available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a69f5f95-6847-4633-9320-2e2eaaf4dcc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Metadata and GPS Insertion Function (4.C) Defined.\n"
     ]
    }
   ],
   "source": [
    "# Task 4.C - 2nd Metadata and GPS Insertion Function\n",
    "\n",
    "def get_exif_with_gps(image_path, latitude, longitude, metadata_sample_path):\n",
    "    \"\"\"\n",
    "    Determines the final EXIF data structure for an image. It either loads\n",
    "    existing metadata, copies it from a sample, and then inserts/updates the GPS location.\n",
    "    \n",
    "    Args:\n",
    "        image_path (pathlib.Path): Path to the original image file.\n",
    "        latitude (float): Project's latitude.\n",
    "        longitude (float): Project's longitude.\n",
    "        metadata_samples (list): List of pathlib.Path objects for sample images.\n",
    "        \n",
    "    Returns:\n",
    "        dict: The complete piexif EXIF dictionary ready to be dumped to bytes.\n",
    "    \"\"\"\n",
    "    # Helper to convert decimal degrees to rational tuple (D, M, S) for EXIF\n",
    "    def to_dms(value):\n",
    "        \"\"\"Converts decimal degrees to a tuple (degrees, minutes, seconds) for EXIF.\"\"\"\n",
    "        if value < 0:\n",
    "            value = -value\n",
    "        d = int(value)\n",
    "        m = int((value - d) * 60)\n",
    "        s = int((value - d - m / 60) * 3600 * 100)\n",
    "        return [(d, 1), (m, 1), (s, 100)]\n",
    "\n",
    "    final_exif_dict = None\n",
    "    \n",
    "    # 1. Load Existing Metadata\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        img_exif_data = img.info.get('exif')\n",
    "        \n",
    "        if img_exif_data:\n",
    "            # piexif.load() will raise an exception if data is malformed\n",
    "            final_exif_dict = piexif.load(img_exif_data)\n",
    "            logger.debug(f\"Loaded existing metadata from {image_path.name}.\")\n",
    "            \n",
    "            # Clean up old GPS data to ensure project coordinates are the source of truth\n",
    "            if \"GPS\" in final_exif_dict:\n",
    "                del final_exif_dict[\"GPS\"] \n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.debug(f\"Could not load valid EXIF data from {image_path.name}: {e}. Attempting fallback.\")\n",
    "\n",
    "    # Define tags for checking valuable camera metadata\n",
    "    MAKE_TAG = 271     # ImageIFD.Make - Camera Manufacturer\n",
    "    MODEL_TAG = 272    # ImageIFD.Model - Camera Model\n",
    "\n",
    "    # [NEW LOGIC] Check if the image has valuable original metadata (Make or Model)\n",
    "    HAS_VALUABLE_METADATA = False\n",
    "    \n",
    "    # Check if the 0th IFD exists\n",
    "    if final_exif_dict and final_exif_dict.get(\"0th\"):\n",
    "        # If either Make or Model tags are present, the metadata is considered valuable and should be preserved.\n",
    "        if MAKE_TAG in final_exif_dict[\"0th\"] or MODEL_TAG in final_exif_dict[\"0th\"]:\n",
    "            HAS_VALUABLE_METADATA = True\n",
    "\n",
    "    # 2. Conditional Metadata Copy/Fallback\n",
    "    \n",
    "    # [MODIFIED CONDITIONAL] Copy sample metadata only if the image is missing the 0th IFD\n",
    "    # OR if it exists but does NOT contain valuable camera metadata (Make or Model).\n",
    "    if final_exif_dict is None or not final_exif_dict.get(\"0th\") or not HAS_VALUABLE_METADATA: \n",
    "        \n",
    "        # Check if the single sample path was provided\n",
    "        if metadata_sample_path:\n",
    "            # Use the pre-selected sample path\n",
    "            sample_path = metadata_sample_path\n",
    "            \n",
    "            try:\n",
    "                # Load EXIF data from the pre-selected sample\n",
    "                sample_img = Image.open(sample_path)\n",
    "                sample_exif_data = sample_img.info.get('exif')\n",
    "                \n",
    "                if sample_exif_data:\n",
    "                    # Copy all metadata from the sample\n",
    "                    final_exif_dict = piexif.load(sample_exif_data)\n",
    "                    \n",
    "                    # Remove sample's GPS data (we'll add the project's in step 3)\n",
    "                    if \"GPS\" in final_exif_dict:\n",
    "                        del final_exif_dict[\"GPS\"] \n",
    "                        \n",
    "                    logger.info(f\"Copied metadata from sample: {sample_path.name} for {image_path.name}.\")\n",
    "                else:\n",
    "                    # Fallback to a bare minimum if sample is also empty\n",
    "                    final_exif_dict = {\"0th\": {}, \"Exif\": {}, \"GPS\": {}, \"1st\": {}}\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Error loading sample metadata from {sample_path.name}: {e}. Using minimum metadata.\")\n",
    "                final_exif_dict = {\"0th\": {}, \"Exif\": {}, \"GPS\": {}, \"1st\": {}}\n",
    "        else:\n",
    "            # Final resort: use a bare minimum EXIF dictionary\n",
    "            final_exif_dict = {\"0th\": {}, \"Exif\": {}, \"GPS\": {}, \"1st\": {}}\n",
    "            logger.warning(f\"No metadata found/copied for {image_path.name}. Using minimum EXIF structure.\")\n",
    "\n",
    "    # 3. GPS Conversion and Insertion (This step always runs)\n",
    "    \n",
    "    # Convert coordinates to DMS format\n",
    "    lat_dms = to_dms(latitude)\n",
    "    lon_dms = to_dms(longitude)\n",
    "\n",
    "    # Determine reference (N/S, E/W)\n",
    "    lat_ref = 'N' if latitude >= 0 else 'S'\n",
    "    lon_ref = 'E' if longitude >= 0 else 'W'\n",
    "\n",
    "    # Create the GPS IFD (Image File Directory) dictionary\n",
    "    gps_ifd = {\n",
    "        piexif.GPSIFD.GPSLatitudeRef: lat_ref,\n",
    "        piexif.GPSIFD.GPSLatitude: lat_dms,\n",
    "        piexif.GPSIFD.GPSLongitudeRef: lon_ref,\n",
    "        piexif.GPSIFD.GPSLongitude: lon_dms,\n",
    "        # Standard GPS Version ID, required by specification\n",
    "        piexif.GPSIFD.GPSVersionID: (2, 2, 0, 0)\n",
    "    }\n",
    "    \n",
    "    # Update the final dictionary with the project's GPS data\n",
    "    final_exif_dict[\"GPS\"] = gps_ifd\n",
    "    \n",
    "    logger.debug(f\"Attached GPS data to EXIF dict: Lat={latitude}, Lon={longitude}\")\n",
    "    \n",
    "    return final_exif_dict\n",
    "\n",
    "print(\"\\n‚úÖ Metadata and GPS Insertion Function (4.C) Defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e9bd5d14-3e27-42d7-b13e-153af6c93a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Optimization, Conversion, and Saving Function (4.D) Defined.\n"
     ]
    }
   ],
   "source": [
    "# Task 4.D: Optimization, Conversion, and Saving Function\n",
    "\n",
    "# Note: This function relies on MAX_FILE_SIZE_BYTES, WEBP_QUALITY, \n",
    "# and the get_exif_with_gps function (4.C) being defined in previous cells.\n",
    "\n",
    "def process_single_image(original_image_name, project_slug, lat, lon, seo_name, metadata_sample_path):\n",
    "    \"\"\"\n",
    "    Handles the end-to-end processing of a single image file: \n",
    "    1. Gets/Copies EXIF data and adds GPS.\n",
    "    2. Opens and optimizes the image (resizing if too large).\n",
    "    3. Converts to WEBP.\n",
    "    4. Saves the final file to the project's folder.\n",
    "    \n",
    "    Args:\n",
    "        original_image_name (str): The filename from the JSON (e.g., 'sample.jpg').\n",
    "        project_slug (str): The project's slug for the output folder.\n",
    "        lat (float): Project latitude.\n",
    "        lon (float): Project longitude.\n",
    "        seo_name (str): The new SEO-friendly base name (from 4.B).\n",
    "        metadata_samples (list): List of sample image paths for EXIF fallback.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (bool success, str status_message, str final_file_name)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Setup Paths\n",
    "    # We must find the full path to the source file (e.g., './RAW_IMAGE_FOLDER/sample.jpg')\n",
    "    source_path = RAW_IMAGE_FOLDER / original_image_name\n",
    "    target_folder = OUTPUT_ROOT_FOLDER / project_slug\n",
    "    final_file_name = f\"{seo_name}.webp\"\n",
    "    final_target_path = target_folder / final_file_name\n",
    "\n",
    "    # Check if the source file exists and has an acceptable extension\n",
    "    if not source_path.is_file() or source_path.suffix.lower() not in IMAGE_EXTENSIONS:\n",
    "        return False, f\"Source file not found or extension not supported: {original_image_name}\", final_file_name\n",
    "\n",
    "    original_size = source_path.stat().st_size\n",
    "    was_resized = False\n",
    "    \n",
    "    try:\n",
    "        # 2. Get EXIF Data (calls 4.C)\n",
    "        final_exif_dict = get_exif_with_gps(source_path, lat, lon, metadata_sample_path)\n",
    "        \n",
    "        # Convert EXIF dictionary back into binary format for saving\n",
    "        exif_bytes = piexif.dump(final_exif_dict)\n",
    "        \n",
    "        # 3. Open Image\n",
    "        img = Image.open(source_path)\n",
    "        width, height = img.size\n",
    "        \n",
    "        # 4. Size Reduction (Scaling): If file size > 300KB, reduce resolution\n",
    "        if original_size > MAX_FILE_SIZE_BYTES:\n",
    "            # We target a max width of 1920px if the image is excessively large, \n",
    "            # as this is a common compromise for web display speed.\n",
    "            MAX_RESIZE_WIDTH = 1920\n",
    "            \n",
    "            if width > MAX_RESIZE_WIDTH:\n",
    "                scale_factor = MAX_RESIZE_WIDTH / width\n",
    "                new_width = MAX_RESIZE_WIDTH\n",
    "                new_height = int(height * scale_factor)\n",
    "                \n",
    "                # Use a high-quality resampling filter (LANCZOS)\n",
    "                img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "                was_resized = True\n",
    "                logger.info(f\"Resized: {original_image_name} from {width}x{height} to {new_width}x{new_height}.\")\n",
    "        \n",
    "        # 5. Handle PNG/Transparency\n",
    "        if img.mode in ('RGBA', 'P') or source_path.suffix.lower() == '.png':\n",
    "            # Create a white background and paste the image, removing the alpha channel\n",
    "            background = Image.new('RGB', img.size, (255, 255, 255))\n",
    "            # Use the alpha channel as a mask if it exists\n",
    "            background.paste(img, mask=img.split()[3] if 'A' in img.mode else None)\n",
    "            img = background\n",
    "            logger.debug(\"Converted image to RGB (removed transparency) for WEBP conversion.\")\n",
    "        \n",
    "        # 6. Convert and Save (WEBP)\n",
    "        img.save(\n",
    "            final_target_path, \n",
    "            \"webp\", \n",
    "            quality=WEBP_QUALITY, \n",
    "            exif=exif_bytes,\n",
    "            method=6 # Use a slightly slower but often better compression method\n",
    "        )\n",
    "\n",
    "        # 7. Final Verification and Status\n",
    "        final_size = final_target_path.stat().st_size\n",
    "        \n",
    "        status_msg = (\n",
    "            f\"Processed successfully. Orig size: {original_size/1024:.1f} KB. \"\n",
    "            f\"Final size: {final_size/1024:.1f} KB. \"\n",
    "            f\"Action: {'Resized and Converted' if was_resized else 'Converted only'}.\"\n",
    "        )\n",
    "        \n",
    "        return True, status_msg, final_file_name\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Catch any failure during the image processing, metadata stamping, or saving\n",
    "        return False, f\"Critical processing error for {original_image_name}: {e}\", final_file_name\n",
    "\n",
    "print(\"\\n‚úÖ Optimization, Conversion, and Saving Function (4.D) Defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "37fbccff-a09c-4c35-a7cd-8ae99f143dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-01 17:03:36,101 - INFO - Starting Task 4: Main Image Processing Pipeline.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e89300f1f82b444dbba75b57bf712367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Overall Projects Progress:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-01 17:03:36,109 - INFO - --- Processing Project: polyester-carpet-dreamweaver-406 (11 images) ---\n",
      "2025-10-01 17:03:36,111 - INFO - Copied metadata from sample: IMG_0194.jpg for crott (1).jpg.\n",
      "2025-10-01 17:03:36,677 - INFO - SUCCESS: polyester-carpet-dreamweaver-406-001-creative-floors-aurora.webp -> Processed successfully. Orig size: 281.1 KB. Final size: 329.8 KB. Action: Converted only.\n",
      "2025-10-01 17:03:36,679 - INFO - Copied metadata from sample: IMG_0194.jpg for crott (2).jpg.\n",
      "2025-10-01 17:03:37,316 - INFO - SUCCESS: polyester-carpet-dreamweaver-406-002-creative-floors-aurora.webp -> Processed successfully. Orig size: 293.1 KB. Final size: 352.7 KB. Action: Converted only.\n",
      "2025-10-01 17:03:37,318 - INFO - Copied metadata from sample: IMG_0194.jpg for crott (3).jpg.\n",
      "2025-10-01 17:03:37,819 - INFO - SUCCESS: polyester-carpet-dreamweaver-406-003-creative-floors-aurora.webp -> Processed successfully. Orig size: 239.3 KB. Final size: 271.2 KB. Action: Converted only.\n",
      "2025-10-01 17:03:37,821 - INFO - Copied metadata from sample: IMG_0194.jpg for bond (1).jpg.\n",
      "2025-10-01 17:03:38,333 - INFO - SUCCESS: polyester-carpet-dreamweaver-406-004-creative-floors-aurora.webp -> Processed successfully. Orig size: 275.7 KB. Final size: 341.4 KB. Action: Converted only.\n",
      "2025-10-01 17:03:38,335 - INFO - Copied metadata from sample: IMG_0194.jpg for giese (1).jpg.\n",
      "2025-10-01 17:03:38,813 - INFO - SUCCESS: polyester-carpet-dreamweaver-406-005-creative-floors-aurora.webp -> Processed successfully. Orig size: 220.6 KB. Final size: 213.4 KB. Action: Converted only.\n",
      "2025-10-01 17:03:38,815 - INFO - Copied metadata from sample: IMG_0194.jpg for crott (4).jpg.\n",
      "2025-10-01 17:03:39,254 - INFO - SUCCESS: polyester-carpet-dreamweaver-406-006-creative-floors-aurora.webp -> Processed successfully. Orig size: 185.5 KB. Final size: 175.1 KB. Action: Converted only.\n",
      "2025-10-01 17:03:39,256 - INFO - Copied metadata from sample: IMG_0194.jpg for bond (2).jpg.\n",
      "2025-10-01 17:03:39,766 - INFO - SUCCESS: polyester-carpet-dreamweaver-406-007-creative-floors-aurora.webp -> Processed successfully. Orig size: 255.1 KB. Final size: 311.0 KB. Action: Converted only.\n",
      "2025-10-01 17:03:39,768 - INFO - Copied metadata from sample: IMG_0194.jpg for bond (3).jpg.\n",
      "2025-10-01 17:03:40,262 - INFO - SUCCESS: polyester-carpet-dreamweaver-406-008-creative-floors-aurora.webp -> Processed successfully. Orig size: 273.6 KB. Final size: 242.3 KB. Action: Converted only.\n",
      "2025-10-01 17:03:40,263 - INFO - Copied metadata from sample: IMG_0194.jpg for giese (2).jpg.\n",
      "2025-10-01 17:03:40,722 - INFO - SUCCESS: polyester-carpet-dreamweaver-406-009-creative-floors-aurora.webp -> Processed successfully. Orig size: 248.9 KB. Final size: 264.3 KB. Action: Converted only.\n",
      "2025-10-01 17:03:40,724 - INFO - Copied metadata from sample: IMG_0194.jpg for giese (3).jpg.\n",
      "2025-10-01 17:03:41,223 - INFO - SUCCESS: polyester-carpet-dreamweaver-406-010-creative-floors-aurora.webp -> Processed successfully. Orig size: 242.1 KB. Final size: 246.6 KB. Action: Converted only.\n",
      "2025-10-01 17:03:41,224 - INFO - Copied metadata from sample: IMG_0194.jpg for giese (4).jpg.\n",
      "2025-10-01 17:03:41,681 - INFO - SUCCESS: polyester-carpet-dreamweaver-406-011-creative-floors-aurora.webp -> Processed successfully. Orig size: 153.3 KB. Final size: 137.6 KB. Action: Converted only.\n",
      "\n",
      "==================================================\n",
      "             ‚ú® PROCESSING SUMMARY ‚ú®\n",
      "==================================================\n",
      "Total Projects:             1\n",
      "Total Images Expected:      11\n",
      "--------------------------------------------------\n",
      "‚úÖ Images Successfully Processed: 11\n",
      "‚ùå Images Failed/Skipped:       0\n",
      "\n",
      "Output Folder:\n",
      "   C:\\wamp64\\www\\media_new\\processed_gallery_images\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Task 4.E: Main Processing Loop\n",
    "\n",
    "logger.info(\"Starting Task 4: Main Image Processing Pipeline.\")\n",
    "\n",
    "# Initialize global counters\n",
    "total_images_found = 0\n",
    "images_processed_success = 0\n",
    "images_processed_failed = 0\n",
    "\n",
    "# Use tqdm (or the DummyTqdm fallback) to show progress across all projects\n",
    "for project in tqdm(PROJECTS_LIST, desc=\"Overall Projects Progress\"):\n",
    "    \n",
    "    slug = project.get('slug')\n",
    "    location = project.get('location', [41.74141971915897, -88.22985634634969]) # Default to Creative Floors HQ\n",
    "    lat, lon = location[0], location[1]\n",
    "    \n",
    "    if not slug or lat is None or lon is None:\n",
    "        logger.error(f\"Skipping project due to missing slug or location data: ID={project.get('id')}.\")\n",
    "        continue\n",
    "    # Select one metadata sample for the entire project\n",
    "    selected_metadata_sample = random.choice(METADATA_SAMPLES) if METADATA_SAMPLES else None\n",
    "    \n",
    "    # 1. Get the list of original image file names (using 4.A)\n",
    "    original_image_names = get_all_image_names(project)\n",
    "    total_images_found += len(original_image_names)\n",
    "    \n",
    "    # Check if any images were found\n",
    "    if not original_image_names:\n",
    "        logger.info(f\"Project '{slug}' has no associated images listed. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    logger.info(f\"--- Processing Project: {slug} ({len(original_image_names)} images) ---\")\n",
    "\n",
    "    # Inner loop: Iterate over all images found for the current project\n",
    "    for original_image_name in original_image_names:\n",
    "        \n",
    "        # 2. Generate SEO-friendly file name (using 4.B)\n",
    "        seo_name = create_seo_name(slug, original_image_name, original_image_names)\n",
    "\n",
    "        # 3. Execute the full processing pipeline (uses 4.C and 4.D logic)\n",
    "        success, status_msg, final_file_name = process_single_image(\n",
    "            original_image_name=original_image_name, \n",
    "            project_slug=slug, \n",
    "            lat=lat, \n",
    "            lon=lon, \n",
    "            seo_name=seo_name, \n",
    "            metadata_sample_path=selected_metadata_sample\n",
    "        )\n",
    "        \n",
    "        # 4. Update Counters and Log\n",
    "        if success:\n",
    "            images_processed_success += 1\n",
    "            logger.info(f\"SUCCESS: {final_file_name} -> {status_msg}\")\n",
    "        else:\n",
    "            images_processed_failed += 1\n",
    "            logger.warning(f\"FAILURE: {original_image_name} -> {status_msg}\")\n",
    "\n",
    "# Final summary printout\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"             ‚ú® PROCESSING SUMMARY ‚ú®\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total Projects:             {TOTAL_PROJECTS}\")\n",
    "print(f\"Total Images Expected:      {total_images_found}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"‚úÖ Images Successfully Processed: {images_processed_success}\")\n",
    "print(f\"‚ùå Images Failed/Skipped:       {images_processed_failed}\")\n",
    "print(\"\\nOutput Folder:\")\n",
    "print(f\"   {OUTPUT_ROOT_FOLDER.resolve()}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if images_processed_failed > 0:\n",
    "    print(\"WARNING: Check the detailed log file (image_processing.log) for failure reasons.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "4767c775-15b0-4388-9234-713bf57338af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the cell that gets the names ... #new format should be a list with images having the first one as thumbnail in the same folder, the project.php is a mess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "78652fd6-424d-4572-af19-fe49c94ca8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "‚ùå PROJECTS WITH AT LEAST ONE IMAGE FAILURE ‚ùå\n",
      "==================================================\n",
      "üéâ All projects completed without a logged image failure.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# Set the log file path\n",
    "log_file_path = 'processed_gallery_images/image_processing.log'\n",
    "\n",
    "# Check if the file exists before attempting to read\n",
    "if not Path(log_file_path).exists():\n",
    "    print(f\"Error: Log file not found at {log_file_path}\")\n",
    "else:\n",
    "    failed_projects = set()\n",
    "    current_project = None\n",
    "    \n",
    "    # Regex to capture the project slug: \"Processing Project: <slug> (<number> images)\"\n",
    "    # It finds the text between \"Processing Project: \" and the opening parenthesis of the image count.\n",
    "    project_start_pattern = re.compile(r\"Processing Project: (.*?) \\(\")\n",
    "    \n",
    "    # Read the log file line by line\n",
    "    with open(log_file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            \n",
    "            # 1. Check for the start of a new project\n",
    "            if \" - INFO - --- Processing Project:\" in line:\n",
    "                match = project_start_pattern.search(line)\n",
    "                if match:\n",
    "                    # Capture the project slug (group 1)\n",
    "                    current_project = match.group(1).strip()\n",
    "                else:\n",
    "                    current_project = None\n",
    "                    \n",
    "            # 2. Check for a failure within the current project\n",
    "            # If a project is being tracked AND we see a failure warning\n",
    "            elif current_project and \" - WARNING - FAILURE:\" in line:\n",
    "                # Add the project slug to the set (sets automatically handle uniqueness)\n",
    "                failed_projects.add(current_project)\n",
    "\n",
    "    # Print the final list of failed projects\n",
    "    print(\"=\" * 50)\n",
    "    print(\"‚ùå PROJECTS WITH AT LEAST ONE IMAGE FAILURE ‚ùå\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if failed_projects:\n",
    "        for project in sorted(list(failed_projects)):\n",
    "            print(f\"    - {project}\")\n",
    "    else:\n",
    "        print(\"üéâ All projects completed without a logged image failure.\")\n",
    "\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3060fae0-63af-4f0d-aaa7-b5424e681021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
